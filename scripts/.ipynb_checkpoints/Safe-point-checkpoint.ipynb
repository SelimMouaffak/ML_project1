{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T02:00:24.993818Z",
     "start_time": "2021-11-01T02:00:22.459028Z"
    }
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from matplotlib import pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the  data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T02:00:33.172475Z",
     "start_time": "2021-11-01T02:00:25.838744Z"
    }
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "#Change the path according to where is your data \n",
    "DATA_TRAIN_PATH = r\"C:\\Users\\USER\\Desktop\\MA1\\ML\\train.csv\" \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T02:00:50.619874Z",
     "start_time": "2021-11-01T02:00:33.174439Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = r\"C:\\Users\\USER\\Desktop\\MA1\\ML\\test.csv\" # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T02:00:50.714616Z",
     "start_time": "2021-11-01T02:00:50.623858Z"
    }
   },
   "outputs": [],
   "source": [
    "### Define variables for the dimensions of the data\n",
    "N = tX.shape[0]\n",
    "D = tX.shape[1]\n",
    "\n",
    "#the number of the feature that contains the pri_jet_number\n",
    "jet_num_col=22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we will partition the data, and then add/delete features, we will fix the column of the jet_num_col to the first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T02:00:50.889150Z",
     "start_time": "2021-11-01T02:00:50.717608Z"
    }
   },
   "outputs": [],
   "source": [
    "# swapping the column with index of\n",
    "# original array\n",
    "tX[:, [jet_num_col, 0]] = tX[:, [0, jet_num_col]]\n",
    "tX_test[:, [jet_num_col, 0]] = tX_test[:, [0, jet_num_col]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T02:00:51.014817Z",
     "start_time": "2021-11-01T02:00:50.896133Z"
    }
   },
   "outputs": [],
   "source": [
    "jet_num_col=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Def func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T23:16:53.778433Z",
     "start_time": "2021-10-28T23:16:53.700290Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### Transform tX by changing -999 with the mean of column\n",
    "def transformTX(tX):\n",
    "    tX2 = np.copy(tX)\n",
    "    tX2[tX2 == -999] = 0\n",
    "    means = np.mean(tX2, axis=0)\n",
    "    for i in range(N):\n",
    "        for j in range(D):\n",
    "            if tX[i][j] == -999:\n",
    "                tX[i][j] = means[j]\n",
    "    return tX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T23:16:53.856504Z",
     "start_time": "2021-10-28T23:16:53.778433Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### Apply log to smoothen data\n",
    "def maybeAddLog(tX):\n",
    "    tX2 = np.copy(tX)\n",
    "    mins = np.min(tX2, axis=0)\n",
    "    for i in range(D):\n",
    "        if mins[i]>0:\n",
    "            for k in range(N):\n",
    "                tX[k][i] = np.log(tX[k][i])\n",
    "    return tX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T23:16:53.935963Z",
     "start_time": "2021-10-28T23:16:53.856504Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### Features Expansion to capture non linear data\n",
    "def featuresExpansion(tX, degree):\n",
    "    res = np.zeros(N).reshape(-1,1)\n",
    "    for i in range(D):\n",
    "        for d in range(1,degree+1):\n",
    "            col = tX[:,i]**d\n",
    "            col = col.reshape(-1,1)\n",
    "            res = np.hstack((res, col))\n",
    "    res = np.delete(res, 0,1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partitioning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T02:00:51.110561Z",
     "start_time": "2021-11-01T02:00:51.018803Z"
    }
   },
   "outputs": [],
   "source": [
    "#div data is a table (that will be changed into a numpy) that will contains the datasets according to their pri_jet_num\n",
    "div_x= [[],[],[]]\n",
    "div_y=[[],[],[]]\n",
    "div_ids=[[],[],[]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T23:16:54.061004Z",
     "start_time": "2021-10-28T23:16:53.998412Z"
    }
   },
   "outputs": [],
   "source": [
    "# tX[i] gives you the ith row, therefore the ith data point\n",
    "# tX[:,j] gives you the jth feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T02:00:51.570712Z",
     "start_time": "2021-11-01T02:00:51.112555Z"
    }
   },
   "outputs": [],
   "source": [
    "#For every data point\n",
    "for i in range (N):\n",
    "    #we extract its pri_jet_num\n",
    "    pri_jet_num=int(tX[i,jet_num_col])\n",
    "    #we assign it to the new data set based on its pri_jet_num\n",
    "    if (pri_jet_num in [0,1]): \n",
    "        div_x[pri_jet_num].append(tX[i])\n",
    "        div_y[pri_jet_num].append(y[i])\n",
    "        div_ids[pri_jet_num].append(ids[i])\n",
    "        \n",
    "    if (pri_jet_num in [2,3]):\n",
    "        div_x[2].append(tX[i]) \n",
    "        div_y[2].append(y[i])\n",
    "        div_ids[2].append(ids[i])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T02:00:51.949660Z",
     "start_time": "2021-11-01T02:00:51.572670Z"
    }
   },
   "outputs": [],
   "source": [
    "#transforming all resultst to numpy arrays\n",
    "for i in range(3):\n",
    "    div_x[i]=np.array(div_x[i])\n",
    "    div_y[i]=np.array(div_y[i])\n",
    "    div_ids[i]=np.array(div_ids[i])\n",
    "\n",
    "div_x=np.array(div_x)\n",
    "div_y=np.array(div_y)\n",
    "div_ids=np.array(div_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T02:00:53.071366Z",
     "start_time": "2021-11-01T02:00:51.951656Z"
    }
   },
   "outputs": [],
   "source": [
    "div_x_test= [[],[],[]]\n",
    "div_id_test=[[],[],[]]\n",
    "N_test=tX_test.shape[0]\n",
    "#For every data point\n",
    "for i in range (N_test):\n",
    "    #we extract its pri_jet_num\n",
    "    pri_jet_num=int(tX_test[i,jet_num_col])\n",
    "    #we assign it to the new data set based on its pri_jet_num\n",
    "    if (pri_jet_num in [0,1]): \n",
    "        div_x_test[pri_jet_num].append(tX_test[i])\n",
    "        div_id_test[pri_jet_num].append( ids_test[i])\n",
    "    if (pri_jet_num in [2,3]):\n",
    "        div_x_test[2].append(tX_test[i])\n",
    "        div_id_test[2].append( ids_test[i])\n",
    "\n",
    "\n",
    "#transforming all resultst to numpy arrays\n",
    "for i in range(3):\n",
    "    div_x_test[i]=np.array(div_x_test[i])\n",
    "\n",
    "div_x_test=np.array(div_x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T02:01:05.845363Z",
     "start_time": "2021-11-01T02:01:05.780959Z"
    }
   },
   "outputs": [],
   "source": [
    "#del_features[i] is False if the feature will be deleated\n",
    "\n",
    "#del_features[i] is for the ith dataset\n",
    "#del_features[:j] is for the jth feature\n",
    "\n",
    "del_features= [[],[],[]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undefined Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T02:01:07.304035Z",
     "start_time": "2021-11-01T02:01:07.242517Z"
    }
   },
   "outputs": [],
   "source": [
    "#takes as input a list of lists called del_features\n",
    "#del_features[i] contains a list of the indices of the features to be deleted in ith dataset \n",
    "def f_del_features(del_features):\n",
    "    for i in range(3):\n",
    "        div_x[i]=np.delete(div_x[i],del_features[i],axis=1)\n",
    "        div_x_test[i]=np.delete(div_x_test[i],del_features[i],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T02:01:09.873919Z",
     "start_time": "2021-11-01T02:01:07.806585Z"
    }
   },
   "outputs": [],
   "source": [
    "# We add all the features that contain only one values\n",
    "for i in range (3):\n",
    "    for j in range(D):\n",
    "        s= set(div_x[i][:,j])\n",
    "        if (len(s)<2):\n",
    "            del_features[i].append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T02:01:11.382429Z",
     "start_time": "2021-11-01T02:01:11.080395Z"
    }
   },
   "outputs": [],
   "source": [
    "f_del_features(del_features)\n",
    "#We reinitialize del_features\n",
    "del_features= [[],[],[]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Correlated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T23:16:59.369529Z",
     "start_time": "2021-10-28T23:16:59.140043Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "corrs=[[],[],[]]\n",
    "for i in range(3):\n",
    "    corrs[i]= np.corrcoef(div_x[i].T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T23:17:00.329211Z",
     "start_time": "2021-10-28T23:16:59.369529Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(i)\n",
    "    sns.heatmap(corrs[i])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T23:17:00.439431Z",
     "start_time": "2021-10-28T23:17:00.331206Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for k in range(3):\n",
    "    corr=corrs[k]\n",
    "    D_k=div_x[k].shape[1]\n",
    "    for i in range(1,D_k):\n",
    "        for j in range(i+1,D_k):\n",
    "            if corr[i,j] >= 0.9:\n",
    "                if j not in del_features[k]:\n",
    "                    del_features[k].append(j)                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T23:17:00.662874Z",
     "start_time": "2021-10-28T23:17:00.522235Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f_del_features(del_features)\n",
    "#We reinitialize del_features\n",
    "del_features= [[],[],[]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## TO ADD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T23:17:00.963709Z",
     "start_time": "2021-10-28T23:17:00.874797Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# tX[i] gives you the ith row, therefore the ith data point\n",
    "# tX[:,j] gives you the jth feature \n",
    "\n",
    "def rescaling(tX):\n",
    "    tX=tX.astype(float)\n",
    "    print(tX.shape)\n",
    "    N=tX.shape[0]\n",
    "    D= tX.shape[1]\n",
    "    for n_feat in range(D):\n",
    "        print(n_feat)\n",
    "        print()\n",
    "        data=tX[n_feat].astype(float)\n",
    "        print(data)\n",
    "        print((data - np.min(data)))\n",
    "        tX[n_feat]=(data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "    return tX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T02:01:18.574384Z",
     "start_time": "2021-11-01T02:01:18.510420Z"
    }
   },
   "outputs": [],
   "source": [
    "### Transform tX by changing -999 with the mean of column\n",
    "def transformTX(tX):\n",
    "    N=tX.shape[0]\n",
    "    D=tX.shape[1]\n",
    "    tX2 = np.copy(tX)\n",
    "    tX2[tX2 == -999] = 0\n",
    "    means = np.mean(tX2, axis=0)\n",
    "    for i in range(N):\n",
    "        for j in range(D):\n",
    "            if tX[i][j] == -999:\n",
    "                tX[i][j] = means[j]\n",
    "    return tX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T02:01:19.278147Z",
     "start_time": "2021-11-01T02:01:19.208550Z"
    }
   },
   "outputs": [],
   "source": [
    "### Apply log to smoothen data\n",
    "def maybeAddLog(tX):\n",
    "    N=tX.shape[0]\n",
    "    D=tX.shape[1]\n",
    "    tX2 = np.copy(tX)\n",
    "    mins = np.min(tX2, axis=0)\n",
    "    for i in range(D):\n",
    "        if mins[i]>0:\n",
    "            for k in range(N):\n",
    "                tX[k][i] = np.log(tX[k][i])\n",
    "    return tX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T02:01:19.947786Z",
     "start_time": "2021-11-01T02:01:19.882573Z"
    }
   },
   "outputs": [],
   "source": [
    "### Features Expansion to capture non linear data\n",
    "def featuresExpansion(tX, degree):\n",
    "    N=tX.shape[0]\n",
    "    D=tX.shape[1]\n",
    "    res = np.zeros(N).reshape(-1,1)\n",
    "    for i in range(D):\n",
    "        for d in range(1,degree+1):\n",
    "            col = tX[:,i]**d\n",
    "            col = col.reshape(-1,1)\n",
    "            res = np.hstack((res, col))\n",
    "    res = np.delete(res, 0,1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T02:02:37.985861Z",
     "start_time": "2021-11-01T02:01:37.924527Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "deg = 7\n",
    "for i in range(3):\n",
    "    print(div_x[i].shape)\n",
    "    div_x[i] = transformTX(div_x[i])\n",
    "    div_x[i] = maybeAddLog(div_x[i])\n",
    "    div_x[i] = featuresExpansion(div_x[i], deg)\n",
    "    \n",
    "    \n",
    "    div_x_test[i] = transformTX(div_x_test[i])\n",
    "    div_x_test[i] = maybeAddLog(div_x_test[i])\n",
    "    div_x_test[i] = featuresExpansion(div_x_test[i], deg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remark: We are assuming that we DO NOT have an offset and that w = {w1, w2, ... , wD} where D=30 in our case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T23:17:18.990100Z",
     "start_time": "2021-10-28T23:17:18.897339Z"
    }
   },
   "outputs": [],
   "source": [
    "### Helper function to select a small set of data (Given in lab2)\n",
    "def batch_iter(y, tx, batch_size, num_batches=1, shuffle=True):\n",
    "    \"\"\"\n",
    "    Generate a minibatch iterator for a dataset.\n",
    "    Takes as input two iterables (here the output desired values 'y' and the input data 'tx')\n",
    "    Outputs an iterator which gives mini-batches of `batch_size` matching elements from `y` and `tx`.\n",
    "    Data can be randomly shuffled to avoid ordering in the original data messing with the randomness of the minibatches.\n",
    "    \"\"\"\n",
    "    data_size = len(y)\n",
    "\n",
    "    if shuffle:\n",
    "        shuffle_indices = np.random.permutation(np.arange(data_size))\n",
    "        shuffled_y = y[shuffle_indices]\n",
    "        shuffled_tx = tx[shuffle_indices]\n",
    "    else:\n",
    "        shuffled_y = y\n",
    "        shuffled_tx = tx\n",
    "    for batch_num in range(num_batches):\n",
    "        start_index = batch_num * batch_size\n",
    "        end_index = min((batch_num + 1) * batch_size, data_size)\n",
    "        if start_index != end_index:\n",
    "            yield shuffled_y[start_index:end_index], shuffled_tx[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T23:17:19.084112Z",
     "start_time": "2021-10-28T23:17:18.992096Z"
    }
   },
   "outputs": [],
   "source": [
    "### Loss function that we use (this function is not used directly but only its gradient)\n",
    "def compute_loss_lin(y, tX, w):\n",
    "    #Calculate the loss using mse\n",
    "    N = tX.shape[0]\n",
    "    e = y - (tX @ w)\n",
    "    return (1/(2*N)) * (e.T @ e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T23:17:19.163258Z",
     "start_time": "2021-10-28T23:17:19.085070Z"
    }
   },
   "outputs": [],
   "source": [
    "### Compute the gradient\n",
    "def compute_gradient_lin(y, tX, w):\n",
    "    N = tX.shape[0]\n",
    "    e = y - (tX @ w)\n",
    "    return (-1/N) * (tX.T @ e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T23:17:19.245166Z",
     "start_time": "2021-10-28T23:17:19.165214Z"
    }
   },
   "outputs": [],
   "source": [
    "### Gradient descent algorithm: the function returns best w\n",
    "def least_squares_GD(y, tX, initial_w, max_iters, gamma):\n",
    "    w = initial_w\n",
    "    for _ in range(max_iters):\n",
    "        grad = compute_gradient_lin(y,tX,w)\n",
    "        w = w - gamma * grad\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T23:17:19.322943Z",
     "start_time": "2021-10-28T23:17:19.246164Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size_linear = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T23:17:19.430904Z",
     "start_time": "2021-10-28T23:17:19.324922Z"
    }
   },
   "outputs": [],
   "source": [
    "### Stochastic gradient descent algorithm: the function returns best w\n",
    "def least_squares_SGD(y, tX, initial_w, max_iters, gamma):\n",
    "    iterate = next(batch_iter(y, tX, batch_size_linear, num_batches=1, shuffle=True))\n",
    "    y1 = iterate[0]\n",
    "    tX1 = iterate[1]\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        grad = compute_gradient_lin(y1,tX1,w)\n",
    "        w = w - gamma * grad\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T02:02:51.820530Z",
     "start_time": "2021-11-01T02:02:51.753460Z"
    }
   },
   "outputs": [],
   "source": [
    "### Least squares regression using normal equations\n",
    "def least_squares(y, tX):\n",
    "    return np.linalg.solve(tX.T@tX,tX.T@y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T23:17:19.617907Z",
     "start_time": "2021-10-28T23:17:19.526649Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### Ridge regression using normal equations \n",
    "def ridge_regression(y, tX, lambda_):\n",
    "    N = tX.shape[0]\n",
    "    D = tX.shape[1]\n",
    "    lambda_prime = 2 * N * lambda_\n",
    "    identity = np.eye(D)\n",
    "    LHS = (tX.T@tX) + lambda_prime*identity\n",
    "    RHS = tX.T@y\n",
    "    \n",
    "    return np.linalg.solve(LHS, RHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T23:17:19.711683Z",
     "start_time": "2021-10-28T23:17:19.620898Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### Helper function to compute sigmoid\n",
    "def sigmoid(t):\n",
    "    \"\"\"apply sigmoid function on t.\"\"\"\n",
    "    return 1.0 / (1 + np.exp(-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T23:17:19.806461Z",
     "start_time": "2021-10-28T23:17:19.713651Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def compute_logistic_loss(y, tx, w):\n",
    "    \"\"\"compute the cost by negative log likelihood.\"\"\"\n",
    "    val = y.T @ np.log(sigmoid(tx@w)) + (1-y.T) @ np.log(1-sigmoid(tx@w))\n",
    "    return np.squeeze(- val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T23:17:19.902239Z",
     "start_time": "2021-10-28T23:17:19.808454Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### Compute the gradient of  \n",
    "def compute_gradient_log(y, tx, w):\n",
    "    return tx.T @ (sigmoid(tx@w) - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T23:17:19.994678Z",
     "start_time": "2021-10-28T23:17:19.904235Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### Logistic regression using gradient descent\n",
    "def logistic_regression_GD(y, tx, initial_w, max_iters, gamma):\n",
    "    w = initial_w\n",
    "    for _ in range(max_iters):\n",
    "        gradient = compute_gradient_log(y, tx, w)\n",
    "        w = w - gamma * gradient\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T23:17:20.090334Z",
     "start_time": "2021-10-28T23:17:19.996546Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batch_size_log = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T23:17:20.201998Z",
     "start_time": "2021-10-28T23:17:20.092293Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### Logisitic regression using stochastic gradient descent \n",
    "def logistic_regression_SGD(y, tx, initial_w, max_iters, gamma):\n",
    "    iterate = next(batch_iter(y, tx, batch_size_log, num_batches=1, shuffle=True))\n",
    "    y1 = iterate[0]\n",
    "    tx1 = iterate[1]\n",
    "    w = initial_w\n",
    "    \n",
    "    for _ in range(max_iters):\n",
    "        gradient = compute_gradient_log(y1, tx1, w)\n",
    "        w = w - gamma * gradient\n",
    "        \n",
    "    return w    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Regularized Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T23:17:20.297864Z",
     "start_time": "2021-10-28T23:17:20.205987Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### Compute regularized gradient\n",
    "def compute_gradient_reg(y, tx, w, lambda_):\n",
    "    return compute_gradient_log(y, tx, w) + lambda_*w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T23:17:20.407625Z",
     "start_time": "2021-10-28T23:17:20.304854Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### Regularized Logistic regression using gradient descent\n",
    "def reg_logistic_regression_GD(y, tx, lambda_, initial_w, max_iters, gamma):\n",
    "    w = initial_w\n",
    "    for _ in range(max_iters):\n",
    "        gradient = compute_gradient_reg(y, tx, w, lambda_)\n",
    "        w = w - gamma * gradient\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T23:17:20.503171Z",
     "start_time": "2021-10-28T23:17:20.409624Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batch_size_reg = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T23:17:20.582860Z",
     "start_time": "2021-10-28T23:17:20.505068Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### Regularized Logisitic regression using stochastic gradient descent \n",
    "def reg_logistic_regression_SGD(y, tx, lambda_, initial_w, max_iters, gamma):\n",
    "    iterate = next(batch_iter(t, tx, batch_size_reg, num_batches=1, shuffle=True))\n",
    "    y1 = iterate[0]\n",
    "    tx1 = iterate[1]\n",
    "    w = initial_w\n",
    "    \n",
    "    for _ in range(max_iters):\n",
    "        gradient = compute_gradient_reg(y1, tx1, w, lambda_)\n",
    "        w = w - gamma * gradient\n",
    "        \n",
    "    return w "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Prediction logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T23:17:20.676311Z",
     "start_time": "2021-10-28T23:17:20.585854Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def predict_labels_logistic(weights, data):\n",
    "    \"\"\"Generates class predictions given weights, and a test data matrix on a logistic regression\"\"\"\n",
    "    y_pred = np.dot(data, weights)\n",
    "    for i in range(len(y_pred)):\n",
    "        y_pred[i] = sigmoid(y_pred[i])\n",
    "    y_pred[np.where(y_pred < 0.5)] = -1\n",
    "    y_pred[np.where(y_pred >= 0.5)] = 1\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T23:17:20.771114Z",
     "start_time": "2021-10-28T23:17:20.677318Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def build_k_indices(y, k_fold, seed):\n",
    "    \"\"\"build k indices for k-fold.\"\"\"\n",
    "    N= y.shape[0]\n",
    "    num_row = N\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval] for k in range(k_fold)]\n",
    "    return np.array(k_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T23:17:20.866857Z",
     "start_time": "2021-10-28T23:17:20.773107Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def cross_validation(y, x, k_indices, k, lambda_, degree):\n",
    "    \"\"\"return the loss of ridge regression.\"\"\"\n",
    "    # get k'th subgroup in test, others in train\n",
    "    te_indice = k_indices[k]\n",
    "    tr_indice = k_indices[~(np.arange(k_indices.shape[0]) == k)]\n",
    "    tr_indice = tr_indice.reshape(-1)\n",
    "    y_te = y[te_indice]\n",
    "    y_tr = y[tr_indice]\n",
    "    x_te = x[te_indice]\n",
    "    x_tr = x[tr_indice]\n",
    "    \n",
    "    w =(y_tr, x_tr)\n",
    "    \n",
    "    y_pred_tr = predict_labels(w, x_tr) \n",
    "    y_pred_te = predict_labels(w, x_te)\n",
    "    # Compare y_pred with y_te\n",
    "    acc_tr = 0\n",
    "    acc_te = 0\n",
    "    for i in range(y_tr.shape[0]):\n",
    "        if y_tr[i] == y_pred_tr[i]:\n",
    "            acc_tr += 1\n",
    "    acc_tr = acc_tr/y_tr.shape[0]\n",
    "    for i in range(y_te.shape[0]):\n",
    "        if y_te[i] == y_pred_te[i]:\n",
    "            acc_te += 1\n",
    "    acc_te = acc_te/y_te.shape[0]\n",
    "    \n",
    "    return acc_tr, acc_te, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T23:17:20.962601Z",
     "start_time": "2021-10-28T23:17:20.871851Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### Defining variables\n",
    "seed = 6\n",
    "degree = 7 #Doesn't matter\n",
    "k_fold = 6\n",
    "lambdas = np.logspace(-4, 0, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T23:17:21.482836Z",
     "start_time": "2021-10-28T23:17:20.965598Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from plots import cross_validation_visualization\n",
    "\n",
    "def cross_validation_demo(n_pri_jet):\n",
    "    # split data in k fold\n",
    "    y=div_y[n_pri_jet]\n",
    "    tX= div_x[n_pri_jet]\n",
    "    k_indices = build_k_indices(y, k_fold, seed)\n",
    "    \n",
    "    # define lists to store the loss of training data and test data\n",
    "    mean_acc_tr = []\n",
    "    mean_acc_te = []\n",
    "    \n",
    "    # cross validation\n",
    "    for lambda_ in lambdas:\n",
    "        mean_acc_tr_tmp = []\n",
    "        mean_acc_te_tmp = []\n",
    "        \n",
    "        for k in range(k_fold):\n",
    "            acc_tr, acc_te,_ = cross_validation(y, tX, k_indices, k, lambda_, degree)\n",
    "            mean_acc_tr_tmp.append(acc_tr)\n",
    "            mean_acc_te_tmp.append(acc_te)\n",
    "        mean_acc_tr.append(np.mean(mean_acc_tr_tmp))\n",
    "        mean_acc_te.append(np.mean(mean_acc_te_tmp))\n",
    "    print(max(mean_acc_te))\n",
    "    cross_validation_visualization(lambdas, mean_acc_tr, mean_acc_te)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for j in range(3):\n",
    "    #cross_validation_demo(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T02:03:00.514165Z",
     "start_time": "2021-11-01T02:03:00.421414Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = r\"C:\\Users\\USER\\Desktop\\MA1\\ML\\output.csv\" # TODO: fill in desired name of output file for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T02:03:12.077677Z",
     "start_time": "2021-11-01T02:03:11.873588Z"
    }
   },
   "outputs": [],
   "source": [
    "###IF WE ARE USING LEAST_SQUARES \n",
    "weights= [[],[],[]]\n",
    "pred=  [[],[],[]]\n",
    "for i in range(3):\n",
    "    weights[i] = least_squares(div_y[i],div_x[i])\n",
    "    pred[i] = predict_labels(weights[i],div_x_test[i] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T02:03:20.154857Z",
     "start_time": "2021-11-01T02:03:19.491187Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred= []\n",
    "ctr= [0,0,0]\n",
    "for i in range(N_test):\n",
    "    pri_jet_num=int(tX_test[i,jet_num_col])\n",
    "    if (pri_jet_num in [0,1]): \n",
    "        idx= ctr[pri_jet_num]\n",
    "        ctr[pri_jet_num]+=1\n",
    "        x= pred[pri_jet_num][idx]\n",
    "        y_pred.append(x)\n",
    "    if (pri_jet_num in [2,3]):\n",
    "        idx= ctr[2]\n",
    "        ctr[2]+=1\n",
    "        x= pred[2][idx]\n",
    "        y_pred.append(x)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T23:17:21.490816Z",
     "start_time": "2021-10-28T23:16:22.962Z"
    }
   },
   "outputs": [],
   "source": [
    "###IF WE ARE USING LOGISTIC REGRESSION\n",
    "y[y == -1] = 0  #We set y's where it is -1 to 0 in order to work with probabilities\n",
    "initial_w = np.random.randint(-1000, 1000, D)\n",
    "max_iters = 1000\n",
    "gamma = 1e-10\n",
    "weights = logistic_regression_GD(y, tX, initial_w, max_iters, gamma)\n",
    "y_pred = predict_labels_logistic(weights, tX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T02:03:32.556022Z",
     "start_time": "2021-11-01T02:03:30.646776Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create submission\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
