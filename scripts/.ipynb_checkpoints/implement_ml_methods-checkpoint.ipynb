{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "#Change the path according to where is your data \n",
    "DATA_TRAIN_PATH = \"C:\\\\Users\\\\Asus-PC\\\\Desktop\\\\ML\\\\Project1\\\\data\\\\train.csv\" \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k = np.zeros(3).reshape(-1,1)\n",
    "kk = np.array([3,3,3]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Transform tX by changing -999 with the mean of column\n",
    "def transformTX(tX):\n",
    "    tX2 = np.copy(tX)\n",
    "    tX2[tX2 == -999] = 0\n",
    "    means = np.mean(tX2, axis=0)\n",
    "    for i in range(tX.shape[0]):\n",
    "        for j in range(tX.shape[1]):\n",
    "            if tX[i][j] == -999:\n",
    "                tX[i][j] = means[j]\n",
    "    return tX\n",
    "\n",
    "def maybeAddLog(tX):\n",
    "    tX2 = np.copy(tX)\n",
    "    mins = np.min(tX2, axis=0)\n",
    "    for i in range(tX.shape[1]):\n",
    "        if mins[i]>0:\n",
    "            for k in range(tX.shape[0]):\n",
    "                tX[k][i] = np.log(tX[k][i])\n",
    "    return tX\n",
    "\n",
    "def normalizeData(tX):\n",
    "    return (tX - np.mean(tX))/np.std(tX)\n",
    "\n",
    "def featuresExpansion(tX, degree):\n",
    "    res = np.zeros(tX.shape[0]).reshape(-1,1)\n",
    "    for i in range(tX.shape[1]):\n",
    "        for d in range(1,degree+1):\n",
    "            col = tX[:,i]**d\n",
    "            col = col.reshape(-1,1)\n",
    "            res = np.hstack((res, col))\n",
    "    res = np.delete(res, 0,1)\n",
    "    return res\n",
    "            \n",
    "tX = transformTX(tX)\n",
    "tX = maybeAddLog(tX)\n",
    "deg = 6\n",
    "tX = featuresExpansion(tX, deg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remark: We are assuming that we DO NOT have an offset and that w = {w1, w2, ... , wD} where D=30 in our case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Helper function to select a small set of data (Given in lab2)\n",
    "def batch_iter(y, tx, batch_size, num_batches=1, shuffle=True):\n",
    "    \"\"\"\n",
    "    Generate a minibatch iterator for a dataset.\n",
    "    Takes as input two iterables (here the output desired values 'y' and the input data 'tx')\n",
    "    Outputs an iterator which gives mini-batches of `batch_size` matching elements from `y` and `tx`.\n",
    "    Data can be randomly shuffled to avoid ordering in the original data messing with the randomness of the minibatches.\n",
    "    \"\"\"\n",
    "    data_size = len(y)\n",
    "\n",
    "    if shuffle:\n",
    "        shuffle_indices = np.random.permutation(np.arange(data_size))\n",
    "        shuffled_y = y[shuffle_indices]\n",
    "        shuffled_tx = tx[shuffle_indices]\n",
    "    else:\n",
    "        shuffled_y = y\n",
    "        shuffled_tx = tx\n",
    "    for batch_num in range(num_batches):\n",
    "        start_index = batch_num * batch_size\n",
    "        end_index = min((batch_num + 1) * batch_size, data_size)\n",
    "        if start_index != end_index:\n",
    "            yield shuffled_y[start_index:end_index], shuffled_tx[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loss function that we use (this function is not used directly but only its gradient)\n",
    "def compute_loss_lin(y, tX, w):\n",
    "    #Calculate the loss using mse\n",
    "    N = y.shape[0]\n",
    "    e = y - (tX @ w)\n",
    "    return (1/(2*N)) * (e.T @ e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compute the gradient\n",
    "def compute_gradient_lin(y, tX, w):\n",
    "    e = y - (tX @ w)\n",
    "    return (-1/N) * (tX.T @ e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Gradient descent algorithm: the function returns best w\n",
    "def least_squares_GD(y, tX, initial_w, max_iters, gamma):\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        grad = compute_gradient_lin(y,tX,w)\n",
    "        w = w - gamma * grad\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Stochastic gradient descent algorithm: the function returns best w\n",
    "def least_squares_SGD(y, tX, initial_w, max_iters, gamma):\n",
    "    batch_size = 1\n",
    "    iterate = next(batch_iter(y, tX, batch_size, num_batches=1, shuffle=True))\n",
    "    y1 = iterate[0]\n",
    "    tX1 = iterate[1]\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        grad = compute_gradient_lin(y1,tX1,w)\n",
    "        w = w - gamma * grad\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Least squares regression using normal equations\n",
    "def least_squares(y, tX):\n",
    "    return np.linalg.solve(tX.T@tX,tX.T@y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ridge regression using normal equations \n",
    "def ridge_regression(y, tx, lambda_):\n",
    "    N = np.shape(tx)[0]\n",
    "    D = np.shape(tx)[1] \n",
    "    lambda_prime = 2 * N * lambda_\n",
    "    identity = np.eye(D)\n",
    "    LHS = (tx.T@tx) + lambda_prime*identity\n",
    "    RHS = tx.T@y\n",
    "    \n",
    "    return np.linalg.solve(LHS, RHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Helper function to compute sigmoid\n",
    "def sigmoid(t):\n",
    "    \"\"\"apply sigmoid function on t.\"\"\"\n",
    "    return 1.0 / (1 + np.exp(-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_logistic_loss(y, tx, w):\n",
    "    \"\"\"compute the cost by negative log likelihood.\"\"\"\n",
    "    val = y.T @ np.log(sigmoid(tx@w)) + (1-y.T) @ np.log(1-sigmoid(tx@w))\n",
    "    return np.squeeze(- val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compute the gradient of  \n",
    "def compute_gradient_log(y, tx, w):\n",
    "    return tx.T @ (sigmoid(tx@w) - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Logistic regression using gradient descent\n",
    "def logistic_regression_GD(y, tx, initial_w, max_iters, gamma):\n",
    "    w = initial_w\n",
    "    for _ in range(max_iters):\n",
    "        gradient = compute_gradient_log(y, tx, w)\n",
    "        w = w - gamma * gradient\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Logisitic regression using stochastic gradient descent \n",
    "def logistic_regression_SGD(y, tx, initial_w, max_iters, gamma):\n",
    "    batch_size = 1\n",
    "    iterate = next(batch_iter(y, tx, batch_size, num_batches=1, shuffle=True))\n",
    "    y1 = iterate[0]\n",
    "    tx1 = iterate[1]\n",
    "    w = initial_w\n",
    "    \n",
    "    for _ in range(max_iters):\n",
    "        gradient = compute_gradient_log(y1, tx1, w)\n",
    "        w = w - gamma * gradient\n",
    "        \n",
    "    return w    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compute regularized gradient\n",
    "def compute_gradient_reg(y, tx, w, lambda_):\n",
    "    return compute_gradient_log(y, tx, w) + lambda_*w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Regularized Logistic regression using gradient descent\n",
    "def reg_logistic_regression_GD(y, tx, lambda_, initial_w, max_iters, gamma):\n",
    "    w = initial_w\n",
    "    for _ in range(max_iters):\n",
    "        gradient = compute_gradient_reg(y, tx, w, lambda_)\n",
    "        w = w - gamma * gradient\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Regularized Logisitic regression using stochastic gradient descent \n",
    "def reg_logistic_regression_SGD(y, tx, lambda_, initial_w, max_iters, gamma):\n",
    "    batch_size = 1\n",
    "    iterate = next(batch_iter(t, tx, batch_size, num_batches=1, shuffle=True))\n",
    "    y1 = iterate[0]\n",
    "    tx1 = iterate[1]\n",
    "    w = initial_w\n",
    "    \n",
    "    for _ in range(max_iters):\n",
    "        gradient = compute_gradient_reg(y1, tx1, w, lambda_)\n",
    "        w = w - gamma * gradient\n",
    "        \n",
    "    return w "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels_logistic(weights, data):\n",
    "    \"\"\"Generates class predictions given weights, and a test data matrix on a logistic regression\"\"\"\n",
    "    y_pred = np.dot(data, weights)\n",
    "    for i in range(len(y_pred)):\n",
    "        y_pred[i] = sigmoid(y_pred[i])\n",
    "    y_pred[np.where(y_pred < 0.5)] = -1\n",
    "    y_pred[np.where(y_pred >= 0.5)] = 1\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_k_indices(y, k_fold, seed):\n",
    "    \"\"\"build k indices for k-fold.\"\"\"\n",
    "    num_row = y.shape[0]\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval] for k in range(k_fold)]\n",
    "    return np.array(k_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(y, x, k_indices, k, lambda_, degree):\n",
    "    \"\"\"return the loss of ridge regression.\"\"\"\n",
    "    # get k'th subgroup in test, others in train\n",
    "    te_indice = k_indices[k]\n",
    "    tr_indice = k_indices[~(np.arange(k_indices.shape[0]) == k)]\n",
    "    tr_indice = tr_indice.reshape(-1)\n",
    "    y_te = y[te_indice]\n",
    "    y_tr = y[tr_indice]\n",
    "    x_te = x[te_indice]\n",
    "    x_tr = x[tr_indice]\n",
    "    # logistic regression\n",
    "    w = ridge_regression(y, tX, lambda_)\n",
    "    # calculate the loss for train and test data\n",
    "    loss_tr = compute_loss_lin(y_tr, x_tr, w)\n",
    "    loss_te = compute_loss_lin(y_te, x_te, w)\n",
    "    return loss_tr, loss_te, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001\n",
      "0.4940200662468936\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plots import cross_validation_visualization\n",
    "\n",
    "def cross_validation_demo():\n",
    "    seed = 6\n",
    "    degree = 7 #Doesn't matter\n",
    "    k_fold = 6\n",
    "    lambdas = np.logspace(-4, 0, 30)\n",
    "    # split data in k fold\n",
    "    k_indices = build_k_indices(y, k_fold, seed)\n",
    "    # define lists to store the loss of training data and test data\n",
    "    rmse_tr = []\n",
    "    rmse_te = []\n",
    "    # cross validation\n",
    "    minimum = 100\n",
    "    mlambda = 0\n",
    "    for lambda_ in lambdas:\n",
    "        rmse_tr_tmp = []\n",
    "        rmse_te_tmp = []\n",
    "        for k in range(k_fold):\n",
    "            loss_tr, loss_te,_ = cross_validation(y, tX, k_indices, k, lambda_, degree)\n",
    "            rmse_tr_tmp.append(loss_tr)\n",
    "            rmse_te_tmp.append(loss_te)\n",
    "        rmse_tr.append(np.mean(rmse_tr_tmp))\n",
    "        rmse_te.append(np.mean(rmse_te_tmp))\n",
    "        if np.mean(rmse_te_tmp) < minimum :\n",
    "            minimum = np.mean(rmse_te_tmp)\n",
    "            mlambda = lambda_\n",
    "\n",
    "    cross_validation_visualization(lambdas, rmse_tr, rmse_te)\n",
    "    print(mlambda)\n",
    "    print(minimum)\n",
    "cross_validation_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = 'C:\\\\Users\\\\Asus-PC\\\\Desktop\\\\ML\\\\Project1\\\\data\\\\test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "##WE ALSO TRANSFORM TX_TEST\n",
    "tX_test = transformTX(tX_test)\n",
    "tX_test = maybeAddLog(tX_test)\n",
    "tX_test = featuresExpansion(tX_test, deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'C:\\\\Users\\\\Asus-PC\\\\Desktop\\\\output.csv' # TODO: fill in desired name of output file for submission\n",
    "\n",
    "###COMMENT ONE OF THE IFs\n",
    "\n",
    "###IF WE ARE USING LEAST_SQUARES \n",
    "weights = least_squares(y,tX)\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "\n",
    "###IF WE ARE USING LOGISTIC REGRESSION\n",
    "# y[y == -1] = 0  #We set y's where it is -1 to 0 in order to work with probabilities\n",
    "# D = tX.shape[1]\n",
    "# initial_w = np.random.randint(-1000, 1000, D)\n",
    "# print(initial_w)\n",
    "# max_iters = 1000\n",
    "# gamma = 1e-10\n",
    "# weights = logistic_regression_GD(y, tX, initial_w, max_iters, gamma)\n",
    "# y_pred = predict_labels_logistic(weights, tX_test)\n",
    "\n",
    "#Create submission\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
